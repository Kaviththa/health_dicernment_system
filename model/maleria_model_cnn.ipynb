{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dedac7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense, Conv2D,MaxPool2D,ZeroPadding2D,Dropout\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94737196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0734c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 64\n",
    "img_width = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f424eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255.0,\n",
    "                                  rotation_range=45,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87e1ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "valdidation_datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b3030cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = train_datagen.flow_from_directory(directory='Dataset\\Train',\n",
    "                                                   target_size=(img_height,img_width),\n",
    "                                                   class_mode='binary',\n",
    "                                                   batch_size=16,\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b082ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_data_generator = valdidation_datagen.flow_from_directory(directory='Dataset\\Test',\n",
    "                                                   target_size=(img_height,img_width),\n",
    "                                                   class_mode='binary',\n",
    "                                                   batch_size=16,\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e984da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16,(3,3),input_shape=(img_height,img_width,3),activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e2a0363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 31, 31, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                401472    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 406,625\n",
      "Trainable params: 406,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24d7a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss ='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93d73be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-7a1df3f8b8e4>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 26 steps, validate for 9 steps\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 14s 529ms/step - loss: 0.7374 - accuracy: 0.5288 - val_loss: 0.6710 - val_accuracy: 0.6791\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.6700 - accuracy: 0.5817 - val_loss: 0.7033 - val_accuracy: 0.3955\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 96ms/step - loss: 0.6273 - accuracy: 0.6514 - val_loss: 0.7150 - val_accuracy: 0.4328\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.5865 - accuracy: 0.6875 - val_loss: 0.7680 - val_accuracy: 0.3507\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 96ms/step - loss: 0.5394 - accuracy: 0.7019 - val_loss: 0.7482 - val_accuracy: 0.4328\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_data_generator,\n",
    "                             steps_per_epoch=len(train_data_generator),\n",
    "                             epochs=5,\n",
    "                             validation_data=validation_data_generator,\n",
    "                             validation_steps = len(validation_data_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad47b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('maleria_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb85cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b728a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img,img_to_array,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "933b1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('dataset/Test/Parasite/C39P4thinF_original_IMG_20150622_110115_cell_126.png', target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da1134d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = img_to_array(img)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5dc3400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.expand_dims(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc7a0935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0bea4f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.vstack([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39d9a252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "08f95b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "Uninfected\n"
     ]
    }
   ],
   "source": [
    "classes= model.predict(images,batch_size=1)\n",
    "print(classes[0])\n",
    "if classes[0] >0.5:\n",
    "    print(\"Uninfected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3f686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
